# 多线程——future

大家还记得前一章，我们讲的计算素数的程序吗？当时我只是说使用Rust重写完毕，但是我并没有说性能怎么样?我当时没敢说。实测结果如下：

```shell
time ./channel02
real    1m11.171s
user    11m34.898s
sys     0m34.985s
```

而go写的相同的计算20000以内的素数所用时间是：

```rust
$ time ./prime 
real	0m0.117s
user	0m1.299s
sys	0m0.008s
```

差距太大了647倍的时间差。这个是怎么回事哪?密码就在rust程序引用的包上——`use std::sync::mpsc;` mpsc是Multiple Producer Single Consumer （多生产者,单消费者FIFO队列。）Rust的通道两端只能有同时由一个线程「拥有」，但是Sender端是可以通过clone来共享给多个线程，这就是所谓的mpsc。

而Go的表现则是一个mpmc(Multiple Producer Multiple Consumer )，多生产者多消费者。

Rust和Go都奉行「通过通信来共享」的原则，Rust要怎么做才能实现和Go一样的效果哪？答案是使用Future。


## Future 基础
Future 的关键定义如下：
```rust
trait Future {
     type Item;
     type Error;
 
     fn poll(&mut self) -> Poll<Self::Item, Self::Error>;
 
     // ...

```

先看一个简单的例子，，我们会用 tokio-core 来实现一个简单的 client，先跟远端的 server 建立连接，给 Server 发送 Hello World，并接受 Server 的返回：
```rust

 extern crate futures;
 extern crate tokio_core; 
 
 use std::net::ToSocketAddrs;
 
 use futures::Future;
 use tokio_core::reactor::Core;
 use tokio_core::net::TcpStream;
 
 fn main() {
     let mut core = Core::new().unwrap();
     let addr = "127.0.0.1:8080".to_socket_addrs().unwrap().next().unwrap();
 
     let socket = TcpStream::connect(&addr, &core.handle());
 
     let request = socket.and_then(|socket| {
         tokio_core::io::write_all(socket, "Hello World".as_bytes())
     });
     let response = request.and_then(|(socket, _)| {
         tokio_core::io::read_to_end(socket, Vec::new())
     });
 
     let (_, data) = core.run(response).unwrap();
     println!("{}", String::from_utf8_lossy(&data));
 }
```
Future 内部定义了两个关联类型，Item 和 Error，极大的方便了用户自定义 Future。

Future 最关键的函数是 `poll`，它会检查当前` future `的状态，看时候已经 `ready`，能对外提供服务，或者出现了错误。

`poll` 返回 `Poll<Self::Item, Self::Error>`，`Poll `是一个 `typedef`，定义如下：

```rust

 pub type Poll<T, E> = Result<Async<T>, E>;
 
 pub enum Async<T> {
     Ready(T),
     NotReady,
 }
 ```
 对于 `Async`，我们知道：

- `Ready(T)` 表明这个` Future` 已经完成，`T` 就是该 `Future `的返回值
- `NotReady `表明这个 `Future `并没有 `ready`，我们需要在后续再次调用 `poll`
在实现自己的 `future` 的时候，我们需要注意，因为 `future `多数都会跟 `event loop `一起使用，所以` poll` 一定不能 `block `整个 `event loop`。如果 `poll `有耗时的操作，我们需要将这些操作放在其他的线程去执行，然后在后续返回结果。

如果 `poll `返回 `NotReady `，表明这个 `Future `并没有完成，我们需要知道何时再次调用这个` future` 的` poll`。所以， 一个 `future` 需要给当前的 `task` 注册一个通知，当这个 `future` 的值已经 `ready`，`task` 会收到这个通知然后让 `future` 继续执行。关于 `task` ，我们后面在继续讨论。

## stream
上面我们说了 `Future` ，在 `futures` 库里面另一个重要的 `trait` 就是 `Stream`。在`Future` 里面，关键的 `poll` 函数其实处理的是一个值的情况，但有些时候，我们需要处理连续流式的值，譬如对于一个 `TCP Listener `来说，它会持续的通过 `accept` 产生新的客户端连接。对于流式的处理，我们使用 `Stream trait`。

```rust
trait Stream {
     type Item;
     type Error;
 
     fn poll(&mut self) -> Poll<Option<Self::Item>, Self::Error>;
 }
 ```

可以看到，`Stream trait` 跟 `Future` 差不多，最大的区别在于 `poll` 返回的是一个 `Option<Self::Item>`，而不是 `Self::Item`。

如果一个 `Stream` 结束了， `poll` 会返回 `Ready(None)`，后续对于该 `Stream` 的错误调用都会 `panic` 。

`Stream` 也是一个特殊的 `Future` ，我们可以使用 `into_future` 函数将 `Stream` 转成一个 `Future` ，这样外面就能使用 `Future` 的 `combinator` （譬如 `and_then``，combinator` 会在后续讨论）将 `Stream` 与其他的 `Future` 连接起来。

## 最终实现的程序

```rust
use std::thread;
use futures_lite::future;
fn generate(tx:   async_channel::Sender<i64>){
    let mut i=2;
    
    loop{
        future::block_on( tx.send(i)).unwrap();
        i+=1;
    }
}

fn filter(src : async_channel::Receiver<i64>, dst:async_channel::Sender<i64>, prime: i64) {
    loop{
        let i=future::block_on(src.recv()).unwrap();
        if i%prime!=0{
            future::block_on(dst.send(i)).unwrap();
        }
    }
}


fn main() {
    let (tx, mut rx) = async_channel::bounded(1);
    thread::spawn(move || generate(tx));
    loop{
        let prime =future::block_on(rx.recv()).unwrap();
	    //println!("{:?}",prime);
        let (tx2,rx2) = async_channel::bounded(7);
        thread::spawn(move || filter(rx,tx2,prime));
        rx=rx2;
        if prime>20000{
            break;
        }
    }
}
```

最终的时间是：

```shell
real    0m0.850s
user    0m3.740s
sys     0m6.006s
```

通过计算素数，我们了解了Rust的多线程。
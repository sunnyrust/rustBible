

# 多线程——future

大家还记得前一章，我们讲的计算素数的程序吗？当时我只是说使用Rust重写完毕，但是我并没有说性能怎么样?我当时没敢说。实测结果如下：

```shell
time ./channel02
real    1m11.171s
user    11m34.898s
sys     0m34.985s
```

而go写的相同的计算20000以内的素数所用时间是：

```rust
$ time ./prime 
real	0m0.117s
user	0m1.299s
sys	0m0.008s
```

差距太大了647倍的时间差。这个是怎么回事哪?密码就在rust程序引用的包上——`use std::sync::mpsc;` mpsc是Multiple Producer Single Consumer （多生产者,单消费者FIFO队列。）Rust的通道两端只能有同时由一个线程「拥有」，但是Sender端是可以通过clone来共享给多个线程，这就是所谓的mpsc。

而Go的表现则是一个mpmc(Multiple Producer Multiple Consumer )，多生产者多消费者。

Rust和Go都奉行「通过通信来共享」的原则，Rust要怎么做才能实现和Go一样的效果哪？答案是使用Future。


## Future 基础
Future 的关键定义如下：
```rust
trait Future {
     type Item;
     type Error;
 
     fn poll(&mut self) -> Poll<Self::Item, Self::Error>;
 
     // ...

```

先看一个简单的例子，，我们会用 tokio-core 来实现一个简单的 client，先跟远端的 server 建立连接，给 Server 发送 Hello World，并接受 Server 的返回：
```rust

 extern crate futures;
 extern crate tokio_core; 
 
 use std::net::ToSocketAddrs;
 
 use futures::Future;
 use tokio_core::reactor::Core;
 use tokio_core::net::TcpStream;
 
 fn main() {
     let mut core = Core::new().unwrap();
     let addr = "127.0.0.1:8080".to_socket_addrs().unwrap().next().unwrap();
 
     let socket = TcpStream::connect(&addr, &core.handle());
 
     let request = socket.and_then(|socket| {
         tokio_core::io::write_all(socket, "Hello World".as_bytes())
     });
     let response = request.and_then(|(socket, _)| {
         tokio_core::io::read_to_end(socket, Vec::new())
     });
 
     let (_, data) = core.run(response).unwrap();
     println!("{}", String::from_utf8_lossy(&data));
 }
```
Future 内部定义了两个关联类型，Item 和 Error，极大的方便了用户自定义 Future。

Future 最关键的函数是 `poll`，它会检查当前` future `的状态，看时候已经 `ready`，能对外提供服务，或者出现了错误。

`poll` 返回 `Poll<Self::Item, Self::Error>`，`Poll `是一个 `typedef`，定义如下：

```rust

 pub type Poll<T, E> = Result<Async<T>, E>;
 
 pub enum Async<T> {
     Ready(T),
     NotReady,
 }
```
 对于 `Async`，我们知道：

- `Ready(T)` 表明这个` Future` 已经完成，`T` 就是该 `Future `的返回值
- `NotReady `表明这个 `Future `并没有 `ready`，我们需要在后续再次调用 `poll`
在实现自己的 `future` 的时候，我们需要注意，因为 `future `多数都会跟 `event loop `一起使用，所以` poll` 一定不能 `block `整个 `event loop`。如果 `poll `有耗时的操作，我们需要将这些操作放在其他的线程去执行，然后在后续返回结果。

如果 `poll `返回 `NotReady `，表明这个 `Future `并没有完成，我们需要知道何时再次调用这个` future` 的` poll`。所以， 一个 `future` 需要给当前的 `task` 注册一个通知，当这个 `future` 的值已经 `ready`，`task` 会收到这个通知然后让 `future` 继续执行。关于 `task` ，我们后面在继续讨论。

## stream
上面我们说了 `Future` ，在 `futures` 库里面另一个重要的 `trait` 就是 `Stream`。在`Future` 里面，关键的 `poll` 函数其实处理的是一个值的情况，但有些时候，我们需要处理连续流式的值，譬如对于一个 `TCP Listener `来说，它会持续的通过 `accept` 产生新的客户端连接。对于流式的处理，我们使用 `Stream trait`。

```rust
trait Stream {
     type Item;
     type Error;
 
     fn poll(&mut self) -> Poll<Option<Self::Item>, Self::Error>;
 }
```

可以看到，`Stream trait` 跟 `Future` 差不多，最大的区别在于 `poll` 返回的是一个 `Option<Self::Item>`，而不是 `Self::Item`。

如果一个 `Stream` 结束了， `poll` 会返回 `Ready(None)`，后续对于该 `Stream` 的错误调用都会 `panic` 。

`Stream` 也是一个特殊的 `Future` ，我们可以使用 `into_future` 函数将 `Stream` 转成一个 `Future` ，这样外面就能使用 `Future` 的 `combinator` （譬如 `and_then``，combinator` 会在后续讨论）将 `Stream` 与其他的 `Future` 连接起来。

## 次最终实现的程序

```rust
use std::thread;
use futures_lite::future;
fn generate(tx:   async_channel::Sender<i64>){
    let mut i=2;
    
    loop{
        future::block_on( tx.send(i)).unwrap();
        i+=1;
    }
}

fn filter(src : async_channel::Receiver<i64>, dst:async_channel::Sender<i64>, prime: i64) {
    loop{
        let i=future::block_on(src.recv()).unwrap();
        if i%prime!=0{
            future::block_on(dst.send(i)).unwrap();
        }
    }
}


fn main() {
    let (tx, mut rx) = async_channel::bounded(1);
    thread::spawn(move || generate(tx));
    loop{
        let prime =future::block_on(rx.recv()).unwrap();
	    //println!("{:?}",prime);
        let (tx2,rx2) = async_channel::bounded(7);
        thread::spawn(move || filter(rx,tx2,prime));
        rx=rx2;
        if prime>20000{
            break;
        }
    }
}
```

次最终的时间是：

```shell
real    0m0.850s
user    0m3.740s
sys     0m6.006s
```

通过计算素数，我们了解了Rust的多线程。

## 最终实现的程序（johnmave126提供）

把线程更换成了tokio来实现，运行速度大幅提升。甚至超过了之前go的程序，看来不是Rust不行，是俺不灵啊。

```toml
[dependencies]
futures = "0.3.17"
tokio = { version = "1.11.0", features = ["full"] }

[profile.release]
opt-level = 3
lto = true
```



```rust
use futures::stream::{self, StreamExt};
use std::iter;
use tokio::sync::mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender};

async fn sieve() {
    let (tx, rx): (UnboundedSender<i32>, UnboundedReceiver<i32>) = unbounded_channel();
    tokio::spawn(async move {
        for i in 2..20000 {
            tx.send(i).ok();
        }
    });
    stream::iter(iter::repeat(()))
        .scan(rx, |rx, _| {
            let (tx2, mut rx2) = unbounded_channel();
            std::mem::swap(rx, &mut rx2);
            async {
                let prime = rx2.recv().await?;
                println!("{}", prime);
                tokio::spawn(async move {
                    while let Some(i) = rx2.recv().await {
                        if i % prime != 0 {
                            tx2.send(i).ok();
                        }
                    }
                });
                Some(())
            }
        })
        .all(|_| std::future::ready(true))
        .await;
}

#[tokio::main]
async fn main() {
    sieve().await;
}
```

运行时间,这个比go稍快。

```shell
real    0m0.104s
user    0m0.345s
sys     0m0.118s
```





> 故事本来以为到了上边已经结束了，但是人生有无限种可能，程序也一样。我把我之前的程序发到了rustcc.cn,网址是：https://rustcc.cn/article?id=b10b7a68-e2bf-42b6-a583-ef99478e50d3 得到了上面tokio的结果(johnmave126 提供），然后这位大神又提供了一个新的思路来解这个问题。



## 大BOSS



johnmave126：

> 筛法本质上其实就是把已知素数表从左到右试一遍
>
> 而且只需要试平方根以内的素数就可以了
>
> 所以可以先生成10以内的素数表，然后用10以内的素数表生成10-100的素数表，拼起来生成100-10000以内的素数表，以此类推
>
> 注意到每次生成的时候，100-10000以内的数都用着同一张已知素数表，所以可以平行化，这里套一个rayon的par_iter来处理



源码如下：

```toml
[dependencies]
rayon = "1.5.1"

[profile.release]
opt-level = 3
lto = true
```



```rust
use rayon::prelude::*;

const N: i32 = 2000000;

fn main() {
    let mut primes = Vec::new();
    let mut cur = 10;
    // bootstrap
    for i in 2..cur {
        if primes.iter().all(|p| i % p != 0) {
            primes.push(i);
        }
    }
    while cur < N {
        let next = std::cmp::min(cur * cur, N);
        let mut addition: Vec<_> = (cur..next)
            .into_par_iter()
            .filter(|x| {
                for p in primes.iter() {
                    if x % p == 0 {
                        return false;
                    }
                    if x / p < *p {
                        break;
                    }
                }
                true
            })
            .collect();
        primes.append(&mut addition);
        cur = next;
    }
    for p in primes {
        println!("{}", p);
    }
}
```





见证奇迹的时刻到了:

```shell
real    0m0.057s
user    0m0.058s
sys     0m0.040s
```



# 多线程——共享

## 共享状态的并发性
消息传递是处理并发的一种好方法，但它不是唯一的方法。不过Go语言文档中有一句口号。"不要通过共享内存进行通信"。我认为非常有道理。

## 使用Mutex
`Mutex`是相互排斥的缩写，就像一个`Mutex`在任何时候只允许一个线程访问一些数据。要访问一个互斥体中的数据，线程必须首先发出信号，要求获得互斥体的锁，以表明它想要访问该数据。锁是一个数据结构，是`mutex`的一部分，它记录了当前谁对数据有独占访问权。因此，`mutex`被描述为通过锁系统来守护它所持有的数据。

Mutexes以难以使用而闻名，因为你必须记住两条规则。

- 你必须在使用数据之前尝试获得锁。
- 当你用完突变体守护的数据后，你必须解锁数据，以便其他线程可以获得锁。

对`mutex`的管理可能是非常棘手的，这就是为什么这么多人热衷于通道。然而，由于Rust的类型系统和所有权规则，你不容易把锁定和解锁弄错。

> 定义：Mutex<T>

与许多类型一样，我们使用相关的函数new创建一个Mutex<T>。为了访问Mutex中的数据，我们使用lock方法来获取锁。这个调用将阻塞当前线程，所以它不能做任何工作，直到轮到我们拥有这个锁。

如果持有锁的另一个线程惊慌失措，对锁的调用就会失败。在这种情况下，没有人能够得到这个锁，所以我们选择了解锁，如果我们遇到这种情况，让这个线程恐慌。

在我们获得锁之后，我们可以将返回值（在本例中名为num）作为内部数据的可变引用。类型系统确保我们在使用m中的值之前获得一个锁：`Mutex<i32>`不是一个`i32`，所以我们必须获得锁才能使用`i32`值。我们不能忘记；否则类型系统将不会让我们访问内部的`i32`。

正如你可能怀疑的，`Mutex<T>`是一个智能指针。更准确地说，对锁的调用返回了一个叫做`MutexGuard`的智能指针，它被包裹在一个`LockResult`中，我们通过调用`unwrap`来处理。`MutexGuard`智能指针实现了`Deref`，以指向我们的内部数据；智能指针也有一个`Drop`实现，当`MutexGuard`超出范围时自动释放锁,因此，我们不会有忘记释放锁的风险，也不会阻止Mutex被其他线程使用，因为锁的释放会自动发生。

在释放锁之后，我们可以打印`mutex`值，并看到我们能够将内部的`i32`改为6。

## 在多个线程之间共享一个Mutex[T]的做法

这个后续我暂时觉着没有太多用处，大家有兴趣自己去看吧<https://doc.rust-lang.org/book/ch16-03-shared-state.html>
